{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining final Project\n",
    "\n",
    "For the project you are going to work in groups of 2.\n",
    "\n",
    "## Aim\n",
    "The aim of this project is to predict molecular properties.  You are going to work with molecular data and you have  to predict 4 molecular properties,  the Octanol-water partition coefficient (logP),  the number of rotatable bonds (RBN),  the molecular weight (MW) and the number of the rings (RN).\n",
    "\n",
    "## Data\n",
    "\n",
    "You are going to work using a subset the QM9 dataset.  The original QM9 dataset [Ramakrishnan et al.,2014)](ttps://www.nature.com/articles/sdata201422), contains $134k $ stable small organic molecules with up to 9 heavy atoms.\n",
    "\n",
    "\n",
    "The data  consists of the following files:\n",
    "1. QM9.txt\n",
    "2. properties_QM9.npz\n",
    "\n",
    "In **QM9.txt** the molecules are represented as SMILES  (Simplified molecular-input line-entry system).  SMILES strings proposed by Weininger (1988),  are non-unique representations which encode the molecular graph into a sequence of ASCII characters using a depth-first graph traversal.\n",
    "\n",
    "For this project we ask you to predict 4 molecular properties,  the Octanol-water partition coefficient (logP),  the  number of rotatable bonds (RBN),  the molecular weight (MW) and the number of the rings (RN).  \n",
    "\n",
    "- logP: represents a measure of the tendency of a compound to move from the aqueous phase into lipids\n",
    "- Number of rotatable bonds (RBN):  the number of bonds which allow free rotation around themselves \n",
    "- Molecular weight (MW): the weight of a molecule based on the atomic masses of all atoms in the molecule\n",
    "- Number of the rings (RN): the number of connected sets of atoms and bonds in which every atom and bond is a member of a cycle\n",
    "\n",
    "**properties\\_QM9.npz** file contains these 4 properties for the QM9.txt data.  \n",
    "\n",
    "\n",
    "## Model\n",
    "Before starting your analysis it is very important to understand the data and the objective of this project.\n",
    "\n",
    "You are free to chose the representation of the data that you are going to use. If you want to work with one-hot-encoding data (see project.pdf for details) you can find the code to convert a single smile string to a one-hot encoding in `smile_to_hot()` function at `utils.py`.\n",
    " You can even use as input data different properties and descriptors (number of bonds,  number of atoms,  number of C, number of O e.t.c. )  that you can extract from your data  manually or using RDKit.  (The properties that we mention are random examples,  there are much more properties and descriptors for the molecules and you have to think what it makes sense for you to use). \n",
    "\n",
    "You are free to try different approaches and models,  you can use ready libraries for your algorithm. The main focus is to see the model you have come up but also the other approaches that you tried. You have to understand deeply all the algorithms that you have tried. \n",
    "\n",
    "\n",
    "\n",
    "Using load\\_data() function in utils.py split the data and the corresponding properties  into train and test.  Use **cross-validation** to select the best model based on **statistical significant test**.  Only for the best model you will use the test data (of course you have to include in your report and present all the models that you have tried).   **It is mandatory to use three or more different algorithms in addition to a baseline**. \n",
    "\n",
    "(The baseline is the naive baseline algorithm,  providing context on just how good a given method actually is.)\n",
    "\n",
    "\n",
    "The final model we would expect is a model that can work on universal data,  which means it can give a reasonable prediction on different molecular datasets.\n",
    " \n",
    "\n",
    "\n",
    "## Report\n",
    "You have to submit a formal report .  Your report has to include the approaches that you followed and main results not only for your final model but for all the models you have tried. We want a full picture of what exactly you have done and how. You should also discuss the different performances you have with your methods and explain why these work or not. What is important is to show us that you have a good understanding of the problem and of how to model it, what are the problems you encountered and how you solved them.\n",
    "\n",
    "\n",
    "Note that this is an open project, you can try many different approaches as long as they make sense to get the best performance (creative ideas are always welcome).\n",
    "\n",
    "## Final submission\n",
    "For your final submission you have to submit on Moodle a folder named using your names (ex. NAME1_NAME2_DM_project) which should include your code (all the scripts), the dataset and your report (the report should also be saved using your names: NAME1_NAME2_DM_project.pdf).  If the size of your submission is big you can upload your submission on [SWITCH drive](https://www.switch.ch) and put on Moodle the shared link. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation Instructions\n",
    "Below you will find some instructions about how to install some packages that required for the project through Conda.\n",
    "\n",
    "[Conda](https://docs.conda.io/en/latest/) is a package manager that works on all the popular operating systems. If you do not already have it installed (e.g. through Anaconda) you can install it via Miniconda by following the instructions [here](https://docs.conda.io/en/latest/miniconda.html) -- it doesn't matter which version of Python you pick at this stage.  We can then setup the particular environment  using the [Conda yml file](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file) I put in the folder of the project.\n",
    "\n",
    "\n",
    "Assuming you have Conda installed,  install the environment by:\n",
    "\n",
    "1. `conda env create -f DM_project_env.yml`\n",
    "2. `conda activate DM_project`\n",
    "3. And then finally check it worked correctly by running \\$ `conda env list`\n",
    "\n",
    "To **activate your enviroment** type: `$ conda activate DM_project`\n",
    "and to deactivete it you should type `$ conda deactivate`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smiles - RDKit\n",
    "\n",
    "Now we will see some examples how we can use RDKit to visualize the molecules and how we can extract different descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rdkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f898ecad71d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# import the parts of RDKit that we need\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mrdkit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAllChem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDraw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'"
     ]
    }
   ],
   "source": [
    "# import the parts of RDKit that we need\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import rdDepictor, rdMolDescriptors\n",
    "\n",
    "\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "\n",
    "import time\n",
    "rdDepictor.SetPreferCoordGen(True)\n",
    "print(rdkit.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If get an error runing the previous cell \n",
    "- first check that you have installed correctly your enviroment (check if you can see it if you type in your termilal `$ conda env list`). \n",
    "- If the enviroment is installed correctly make sure that you have activated it (`$ conda activate DM_project`) before you opened the jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Reading in SMILES strings\n",
    "\n",
    "SMILES (Simplified molecular-input line-entry system) proposed by Weininger (1988) is a popular method to represent molecules as ASCII strings. The string is created by printing out the nodes found on a traversal of the molecular graph. The idea behind is to use simple line notations for chemical formulas that are based on some rules.\n",
    "\n",
    "\n",
    "Atoms of chemical elements are represented by chemical symbols in capital letter, hydrogen is usually ignored. Single bonds are not displayed; for double, triple and quadruple bonds we shall use '=', '#', '$' respectively. Atoms that are bonded must stand nearby. Ring structures are written by breaking each ring at an arbitrary point (although some choices will lead to a more legible SMILES than others) to make a 'straight non-ring' structure (as if it wasn't a ring) and adding numerical ring closure labels to show connectivity between non-adjacent atoms. Aromacity is commonly illustrated by writing the constituent B, C, N, O, P and S atoms in lower-case forms b, c, n, o, p and s, respectively.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDKit\n",
    "\n",
    "\n",
    "RDKit is a collection of cheminformatics and machine learning tools written in C++ and Python. It allows to work with many representations of chemical data and has a power to extract almost each chemical descriptor from the data you have. \n",
    "\n",
    "You can learn more about how to use RDKit, in the RDKit [documentation](http://www.rdkit.org/docs/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RDKit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining a string variable containing the SMILES representation of the paracetemol (i.e. acetaminophen) molecule, a popular painkiller and reading it into RDKit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of molecules\n",
    "\n",
    "In order to visualize the the SMILES we have to convert them to molecules. This happened running `Chem.MolFromSmiles`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paracetemol_str = 'CC(=O)Nc1ccc(O)cc1'\n",
    "\n",
    "# convert smile to mol\n",
    "paracetemol_mol = Chem.MolFromSmiles(paracetemol_str)\n",
    "\n",
    "# visualize mol\n",
    "Draw.MolToImage(paracetemol_mol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have converted the SMILES to a RDKit `Mol` object (which happened when running `Chem.MolFromSmiles`) we can manipulate it in different ways. For example, we can iterate through the atoms or bonds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the atoms. Print their symbol,  atomic number, and number of Hydrogens\n",
    "for atm in paracetemol_mol.GetAtoms():\n",
    "    print(f\"Atom element: {atm.GetSymbol()}, atomic number: {atm.GetAtomicNum()}, number of hydrogens {atm.GetTotalNumHs()}\")\n",
    "\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# Iterate through the bonds\n",
    "for bnd in paracetemol_mol.GetBonds():\n",
    "    print(f\"Bond from {bnd.GetBeginAtomIdx()} to {bnd.GetEndAtomIdx()} and is of type {bnd.GetBondType()}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we iterated through the atoms we also printed the number of hydrogen atoms attached. You may have spotted that these hydrogen atoms were not included in the original SMILES string. In general we ignore the hydrogen atoms (they are treated implicitly) but we can include them in SMILES strings if we wanted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Chem.MolToSmiles(paracetemol_mol, allHsExplicit=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers of atoms of molecule\n",
    "\n",
    "The size of a molecule can be approximated by a number of atoms in it. Let's extract corresponding values from MOL. RDkit provides GetNumAtoms() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AddHs function adds H atoms to a MOL (as Hs in SMILES are usualy ignored)\n",
    "# GetNumAtoms() method returns a general nubmer of all atoms in a molecule including H\n",
    "\n",
    "\n",
    "paracetemol_mol_with_H = Chem.AddHs(paracetemol_mol)\n",
    "\n",
    "print('Number of total atoms in paracetamol :', paracetemol_mol_with_H.GetNumAtoms())\n",
    "print('Number of atoms in paracetamol (excluding H):', paracetemol_mol.GetNumAtoms())\n",
    "\n",
    "paracetemol_mol_with_H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptors\n",
    "A number of general molecular descriptors that can also be used to featurize a molecule are provided by `rdkit.Chem.Descriptors` and `rdkit.Chem.rdMolDescriptors`. Bellow we can see some examples. More examples and a detailed descripton you can find in **RDKit** documantation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptors.HeavyAtomCount returns a nubmer of all atoms in a molecule with molecular weight > 1\n",
    "# Descriptors.HeavyAtomMolWt the average molecular weight of the molecule ignoring hydrogens\n",
    "# Descriptors.MolLogP returns the Octanol-water partition coefficient\n",
    "# Descriptors.qed returns the drug-likeness \n",
    "# Descriptors.MolW returns the Molecular weight\n",
    "# Descriptors.NumRotatableBonds returns the number of rotatable bond\n",
    "# ...\n",
    "\n",
    "desc_HeavyAtomCount = Descriptors.HeavyAtomCount(paracetemol_mol)\n",
    "desc_HeavyAtomMolWt = Descriptors.HeavyAtomMolWt(paracetemol_mol)\n",
    "desc_MolLogP = Descriptors.MolLogP(paracetemol_mol)\n",
    "desc_qed = Descriptors.qed(paracetemol_mol)\n",
    "desc_MolWt = Descriptors.MolWt(paracetemol_mol)\n",
    "desc_NumRotatableBonds = Descriptors.NumRotatableBonds(paracetemol_mol)\n",
    "\n",
    "print('Number of heavy atoms in paracetamol:', desc_HeavyAtomCount)\n",
    "print('Average molecular weight ignoring hydrogens:', desc_HeavyAtomMolWt)\n",
    "\n",
    "print('logP in paracetamol:', desc_MolLogP)\n",
    "print('drug-likeness:', desc_qed)\n",
    "print('Molecular weight:', desc_MolWt)\n",
    "\n",
    "\n",
    "# rdMolDescriptors.CalcNumRings returns the number of rings for a molecule\n",
    "# rdMolDescriptors.CalcNumHBD returns the number of H-bond donors for a molecule\n",
    "# rdMolDescriptors.CalcNumHBA returns the number of H-bond acceptors for a molecule\n",
    "# ...\n",
    "\n",
    "num_rings = rdMolDescriptors.CalcNumRings(paracetemol_mol)\n",
    "num_H_donors = rdMolDescriptors.CalcNumHBD(paracetemol_mol)\n",
    "num_H_acceptors = rdMolDescriptors.CalcNumHBA(paracetemol_mol)\n",
    "\n",
    "print('Number of ring:', num_rings)\n",
    "print('Number of H-bond donors:', num_H_donors)\n",
    "print('Number of H-bond acceptors:', num_H_acceptors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and viewing a set of example molecules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naphthalene = Chem.MolFromSmiles('c12ccccc1cccc2')\n",
    "benzoxazole = Chem.MolFromSmiles('n1c2ccccc2oc1')\n",
    "indane = Chem.MolFromSmiles('c1ccc2c(c1)CCC2')\n",
    "skatole = Chem.MolFromSmiles('CC1=CNC2=CC=CC=C12')\n",
    "benzene = Chem.MolFromSmiles('c1ccccc1')\n",
    "quinoline = Chem.MolFromSmiles('n1cccc2ccccc12')\n",
    "\n",
    "my_molecules = [naphthalene, \n",
    "                benzoxazole,\n",
    "                indane,\n",
    "                skatole,\n",
    "                benzene,\n",
    "                quinoline,\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to get a look at the structure of these molecules.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Draw.MolsToGridImage(my_molecules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing QM9 dataset and properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_smiles_encodings, load_data, smile_to_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_smiles = './dataset/QM9.txt'\n",
    "# get smiles, alphabet and length of largest molecule in SMILES from the dataset\n",
    "smiles, alphabet, largest_molecule_len = get_smiles_encodings(file_smiles)\n",
    "\n",
    "print(alphabet)\n",
    "print(\"\\n\")\n",
    "print(largest_molecule_len)\n",
    "print(\"\\n\")\n",
    "print(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_properties = './dataset/properties_QM9.npz'\n",
    "\n",
    "# load the properties: logP, RBN, MW, RN\n",
    "properties = np.load(file_properties)['properties'].astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data(smiles, properties)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', type(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a single smile string to a one-hot encoding\n",
    "idx = 636\n",
    "integer_encoded, onehot_smile = smile_to_hot(X_train[idx], largest_molecule_len, alphabet)\n",
    "\n",
    "print(integer_encoded)\n",
    "print(onehot_smile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('smile string:', X_train[idx])\n",
    "print('one-hot encoded smile:', onehot_smile)\n",
    "\n",
    "print(integer_encoded)\n",
    "print(len(integer_encoded))\n",
    "mol = Chem.MolFromSmiles(X_train[idx])\n",
    "\n",
    "Draw.MolToImage(mol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this project we want to predict 4 molecular properties:\n",
    "\n",
    "The Octanol-water partition coeﬀicient (logP),\n",
    "the number of rotatable bonds (RBN), \n",
    "the molecular weight (MW), \n",
    "and the number of the rings (RN).\n",
    "\n",
    "The representation of the data that we are going to use is one-hot encoding. we convert a single smile string to a one-hot encoding using smile_to_hot(). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(properties.shape)\n",
    "\n",
    "\n",
    "props= properties[::500] \n",
    "fig = plt.figure(figsize=(14,9))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(range(props.shape[0]),props[:,0])\n",
    "plt.title('property number 1: the Octanol-water partition coeﬀicien')\n",
    "\n",
    "props= properties[:] \n",
    "plt.subplot(2,2,2)\n",
    "plt.scatter(range(props.shape[0]),props[:,1])\n",
    "plt.title('property number 2: the number of rotatable bonds (RBN)')\n",
    "\n",
    "\n",
    "props= properties[::500] \n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(range(props.shape[0]),props[:,2])\n",
    "plt.title('property number 3: the molecular weight (MW)')\n",
    "\n",
    "\n",
    "props= properties[:] \n",
    "plt.subplot(2,2,4)\n",
    "plt.scatter(range(props.shape[0]),props[:,3])\n",
    "plt.title('property number 4: the number of the rings (RN)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing a proper method for Data Analysis \n",
    "\n",
    "LogP : since both the Octanol-water partition coeﬀicient and molecular weight are continuous datas, we choose Linear regression to predict those properties. Thus, we use a regressor.\n",
    "\n",
    "\n",
    "RBN: as we can see in the top figure, the number of rotable bonds for each molcule is a member of the set S = {0 , 1 , 2 , 3 , 4} which means molecules can be classified in 5 different classes. So we should use a classification method to predict the RBN of a molecule. The same reason for the property number 4,the number of the rings RN, thus we use a classification method as well. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding the all smiles to integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_IC = []     # X_train Integer Encoded\n",
    "X_test_IC = []      # X_test Integer Encoded\n",
    "\n",
    "X_train_OH = []     # X_train one-hot encoded\n",
    "X_test_OH = []      # X_test one-hot encoded\n",
    "\n",
    "\n",
    "for idx in range(len(X_train)):\n",
    "    integer_encoded, onehot_smile = smile_to_hot(X_train[idx], largest_molecule_len, alphabet)\n",
    "    X_train_IC.append(integer_encoded)\n",
    "    X_train_OH.append(onehot_smile.flatten())\n",
    "\n",
    "for idx in range(len(X_test)):\n",
    "    integer_encoded, onehot_smile = smile_to_hot(X_train[idx], largest_molecule_len, alphabet)\n",
    "    X_test_IC.append(integer_encoded)\n",
    "    X_test_OH.append(onehot_smile.flatten())\n",
    "\n",
    "X_train_IC = np.array(X_train_IC)\n",
    "X_test_IC = np.array(X_test_IC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# mean = 0 , std = 1\n",
    "\n",
    "X = np.concatenate((X_train_IC,X_test_IC))\n",
    "Normalized_X = preprocessing.normalize(X)\n",
    "\n",
    "Normal_X_train_IC = Normalized_X[0:len(X_train_IC)]\n",
    "Normal_X_test_IC = Normalized_X[(len(X_train_IC)):]\n",
    "\n",
    "print(Normal_X_test_IC.shape)\n",
    "print(Normal_X_train_IC.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integer encoded form of smiles are made of, well, integer numbers unsurprisingly, so train_nb detect them as categorical data which caused an error so we have to normalize the data to introduce them to train_nb as continuous data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression for 1th and 3rd atribute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First atribute :\n",
    "Regression based ridge regression, with l2 regularisation, using the analitical formula to find the least square of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from regression import LinearRegression_RidgeRegression\n",
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "y_tr = y_train[:,0]\n",
    "y_ts = y_test[:,0]\n",
    "\n",
    "\n",
    "y_tr = np.reshape(y_tr,(y_tr.shape[0],1)) # we change the shape of y_tr from (m,) to (m,1)\n",
    "\n",
    "\n",
    "model= LinearRegression_RidgeRegression(Normal_X_train_IC, y_tr , iterations=50, lr=0.001, l2_reg =10000, \n",
    "                                          analytical_sol=True)\n",
    "                                        #,SGD=True, BatchNumber = int(Normal_X_train_IC.shape[0]/10))\n",
    "\n",
    "    \n",
    "print('Normal_X_train_IC shape: ',Normal_X_train_IC.shape)\n",
    "print('y_train shape: ',y_train.shape)\n",
    "w = model.fit()\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model.predict(Normal_X_test_IC)\n",
    "y_pred = y_pred.reshape(y_pred.shape[0]) # reduce dimention  \n",
    "print('y_pred : ', y_pred.shape)\n",
    "\n",
    "\n",
    "y_ts = np.reshape(y_ts,(y_ts.shape[0],1))\n",
    "y_ts = y_ts.flatten()  # reduce dimension for MSE cacule \n",
    "print('y_ts: ',y_ts.shape)\n",
    "\n",
    "\n",
    "\n",
    "MSE = abs (np.sum((y_pred-y_ts)**2)) / y_test.shape[0]\n",
    "print(\"\\nThe MSE is : %0.5E\" %(MSE) )\n",
    "\n",
    "\n",
    "#print('y_test shape: ',y_test.shape[0])\n",
    "#print('y_ts shape: ',y_ts.shape)\n",
    "#print('y_pred shape: ',y_pred.shape[0])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(y_pred - y_ts, 50)\n",
    "plt.title('histogarm of diffrence between predicted(LogP) and real(LogP)')\n",
    "\n",
    "print(\"--- %s seconds ---\" % np.round((time.time() - start_time),2))\n",
    "\n",
    "\n",
    "# un classificateur qui rend average of the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first atribute :\n",
    "Regression based ridge regression, with l2 regularisation, using gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from regression import LinearRegression_RidgeRegression\n",
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "y_tr = y_train[:,0]\n",
    "y_ts = y_test[:,0]\n",
    "\n",
    "\n",
    "y_tr = np.reshape(y_tr,(y_tr.shape[0],1)) # we change the shape of y_tr from (m,) to (m,1)\n",
    "\n",
    "\n",
    "model_SGD= LinearRegression_RidgeRegression(Normal_X_train_IC, y_tr , iterations=50, lr=0.001, l2_reg =10, \n",
    "                                          analytical_sol=False, SGD=True, BatchNumber = int(Normal_X_train_IC.shape[0]/10))\n",
    "\n",
    "    \n",
    "print('Normal_X_train_IC shape: ',Normal_X_train_IC.shape)\n",
    "print('y_train shape: ',y_train.shape)\n",
    "w = model_SGD.fit()\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model_SGD.predict(Normal_X_test_IC)\n",
    "y_pred = y_pred.reshape(y_pred.shape[0])\n",
    "print('y_pred : ', y_pred.shape)\n",
    "\n",
    "\n",
    "y_ts = np.reshape(y_ts,(y_ts.shape[0],1))\n",
    "y_ts = y_ts.flatten()\n",
    "print('y_ts: ',y_ts.shape)\n",
    "\n",
    "\n",
    "\n",
    "MSE = abs (np.sum((y_pred-y_ts)**2)) / y_test.shape[0]\n",
    "print(\"\\nThe MSE is : %0.5E\" %(MSE) )\n",
    "\n",
    "\n",
    "\n",
    "print('y_test shape: ',y_test.shape[0])\n",
    "print('y_ts shape: ',y_ts.shape)\n",
    "print('y_pred shape: ',y_pred.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(y_pred - y_ts, 50)\n",
    "plt.title('histogarm of diffrence between predicted(LogP) and real(LogP)')\n",
    "print('\\n')\n",
    "\n",
    "print(\"--- %s seconds ---\" % np.round((time.time() - start_time),2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# third atribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analical = true , \n",
    "#anatical = false and SGD = false and change des itérations\n",
    "#analical = true , regul= 10\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from regression import LinearRegression_RidgeRegression\n",
    "\n",
    "y_tr = y_train[:,2]\n",
    "y_ts = y_test[:,2]\n",
    "\n",
    "\n",
    "y_tr = np.reshape(y_tr,(y_tr.shape[0],1))  # we change the shape of y_tr from (m,) to (m,1)\n",
    "\n",
    "\n",
    "model = LinearRegression_RidgeRegression(Normal_X_train_IC, y_tr, iterations=40, lr=0.05, l2_reg =0, \n",
    "                                          analytical_sol=False, SGD=True, BatchNumber = int(Normal_X_train_IC.shape[0]/10))\n",
    "\n",
    "\n",
    "#print('Normal_X_train_IC: ',Normal_X_train_IC.shape)\n",
    "#print('y_train shape: ',y_train.shape)\n",
    "w = model.fit()\n",
    "#print(\"\\nThe main w is : \" , W.T)\n",
    "#print(\"The Predicted w is : \" , w[:-1].T)\n",
    "\n",
    "\n",
    "y_pred = model.predict(Normal_X_test_IC)\n",
    "print('y_predy:', y_pred.shape)            #(39612, 1)\n",
    "y_pred = y_pred.reshape(y_pred.shape[0])   # reduce dimention  \n",
    "print('y_predy:', y_pred.shape)            #(39612,)\n",
    "\n",
    "\n",
    "print('y_ts shape: ',y_ts.shape)\n",
    "y_ts = np.reshape(y_ts,(y_ts.shape[0],1)) # we change the shape of y_tr from (m,) to (m,1)\n",
    "print('y_ts shape: ',y_ts.shape)\n",
    "y_ts = y_ts.flatten()\n",
    "\n",
    "\n",
    "MSE = abs (np.sum((y_pred - y_ts)**2)) / y_test.shape[0]  #39612\n",
    "print( y_test.shape[0])\n",
    "print(\"\\nThe MSE is : %0.5E\" %(MSE) )\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(y_pred - y_ts, 50)\n",
    "plt.title('histogarm of diffrence between predicted(MW) and real(MW)')\n",
    "\n",
    "print(\"--- %s seconds ---\" % np.round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn.naive_bayes as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nb import train_nb,normal_distribution, predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr2 = y_train[:,1]\n",
    "print(Normal_X_train_IC.shape)\n",
    "print(y_tr2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior, mean, std = train_nb(Normal_X_train_IC, y_tr2)\n",
    "print('Prior: ', prior)\n",
    "print('mean: ', freq)\n",
    "print('std:', std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL = np.unique (y_tr2)    \n",
    "ClassLabels = np.unique([str(int(e)) for e in CL])\n",
    "print(np.unique (ClassLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the train accuracy:\n",
    "y_train_pred = predict(Normal_X_train_IC, prior, mean, std)\n",
    "num_correct_train = np.sum([1 for ytp, yt in zip(y_train_pred,y_train[:,1]) if ytp == yt])\n",
    "accuracy_train = num_correct_train / len(y_train[:,1])\n",
    "print('Train: Got %d / %d correct => accuracy: %f' % (num_correct_train, len(y_train), accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the train accuracy:\n",
    "y_test_pred = predict(Normal_X_test_IC, prior, mean, std)\n",
    "num_correct_test = np.sum([1 for ytp, yt in zip(y_test_pred,y_test[:,1]) if ytp==yt])\n",
    "accuracy_test = num_correct_test / len(y_test[:,1])\n",
    "print('Train: Got %d / %d correct => accuracy: %f' % (num_correct_test, len(y_test), accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4th atribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr4 = y_train[:,3]\n",
    "print(Normal_X_train_IC.shape)\n",
    "print(y_tr4.shape)\n",
    "\n",
    "prior, mean, std = train_nb(Normal_X_train_IC, y_tr4)\n",
    "print('Prior: ', prior)\n",
    "print('mean: ', freq)\n",
    "print('std:', std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL = np.unique (y_tr4)\n",
    "ClassLabels = np.unique([str(int(e)) for e in CL])\n",
    "print(np.unique (ClassLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the train accuracy:\n",
    "y_train_pred = predict(Normal_X_train_IC, prior, mean, std)\n",
    "num_correct_train = np.sum([1 for ytp, yt in zip(y_train_pred,y_train[:,3]) if ytp==yt])\n",
    "accuracy_train = num_correct_train / len(y_train[:,3])\n",
    "print('Train: Got %d / %d correct => accuracy: %f' % (num_correct_train, len(y_train), accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the train accuracy:\n",
    "y_test_pred = predict(Normal_X_test_IC, prior, mean, std)\n",
    "num_correct_test = np.sum([1 for ytp, yt in zip(y_test_pred,y_test[:,3]) if ytp==yt])\n",
    "accuracy_test = num_correct_test / len(y_test[:,3])\n",
    "print('Train: Got %d / %d correct => accuracy: %f' % (num_correct_test, len(y_test), accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classification\n",
    "### 2nd atribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open distances.py and implement compute_mahalanobis_dist.\n",
    "from distances import compute_mahalanobis_dist, compute_euclidean_dist_one_loop\n",
    "from distances import define_covariance\n",
    "\n",
    "\n",
    "# mahalanobis distance\n",
    "d = Normal_X_train_IC.shape[1]\n",
    "identity = np.identity(d)\n",
    "dists_maha = compute_mahalanobis_dist(Normal_X_train_IC, Normal_X_test_IC, identity)\n",
    "\n",
    "# To ensure that our new implementation is correct, the test below will compare it to the\n",
    "# naive one using the norm.\n",
    "# we should expect a value close to 0.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
